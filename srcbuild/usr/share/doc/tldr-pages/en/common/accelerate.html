<h1>accelerate</h1>

<blockquote><p>A library that enables the same PyTorch code to be run across any distributed configuration.
More information: <a href="https://huggingface.co/docs/accelerate/index">https://huggingface.co/docs/accelerate/index</a>.</p></blockquote>

<ul>
<li>Print environment information:</li>
</ul>


<p><code>accelerate env</code></p>

<ul>
<li>Interactively create a configuration file:</li>
</ul>


<p><code>accelerate config</code></p>

<ul>
<li>Print the estimated GPU memory cost of running a Hugging Face model with different data types:</li>
</ul>


<p><code>accelerate estimate-memory {{name/model}}</code></p>

<ul>
<li>Test an Accelerate configuration file:</li>
</ul>


<p><code>accelerate test --config_file {{path/to/config.yaml}}</code></p>

<ul>
<li>Run a model on CPU with Accelerate:</li>
</ul>


<p><code>accelerate launch {{path/to/script.py}} {{--cpu}}</code></p>

<ul>
<li>Run a model on multi-GPU with Accelerate, with 2 machines:</li>
</ul>


<p><code>accelerate launch {{path/to/script.py}} --multi_gpu --num_machines 2</code></p>
